# -*- coding: utf-8 -*-
"""lab3_TensorFlow 2 - CIFAR-100.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1qcyOlb73frJTcT2uLrmdbkbvK6EfMhm2

# Neural Networks and Intelligent Systems
# NTUA AILS Lab
## Lab Exercise 3:
$\textbf{Introduction to Deep Learning: Convolutional Neural Networks and TensorFlow 2.1.0}$

## Team MA7
### KONTOGIANNIS ANDREAS (03115187)
### SPYROU NIKOLAOS (03116201)
### PEPPAS PANAGIOTIS (03115146)

# Εισαγωγή
Ο βασικός στόχος της παρούσας άσκησης είναι η εξοικείωση με τη βιβλιοθήκη **TensorFlow 2**. Κάθε ομάδα θα δουλέψει σε ένα διαφορετικό υποσύνολο του συνόλου δεδομένων **CIFAR-100**.

# TensorFlow 2 (vs TensorFlow 1)

![alt text](https://miro.medium.com/max/4928/1*-QTg-_71YF0SVshMEaKZ_g.png)
Η βιβλιοθήκη TensorFlow 2 διαδέχθηκε την TensorFlow 1 τον Οκτώβριο του 2019 και η τελευταία έκδοσή της αυτή τη στιγμή είναι η 2.1.0 (8 Ιανουαρίου 2020). 

Οι δύο πιο σημαντικές διαφορές του TensorFlow 2 σε σχέση με το TensorFlow 1 είναι οι εξής:

1. **Απλοποίηση της χρήσης - Keras API**: το tf2 χρησιμοποιεί πλέον ως high-level API το tf.keras, δηλαδή τη δική του υλοποίηση της προδιαγραφής API του Keras. Επίσης διάφορα δομοστοιχεία του tf1 αφαιρέθηκαν, συγχωνεύθηκαν ή μετακινήθηκαν σε υποπακέτα ώστε να “καθαρίσει” o ονοματοχώρος tf.*.

2. **Πρόθυμη εκτέλεση (Eager execution)**: στο tf1 το γράψιμο του κώδικα χωρίζεται σε δύο μέρη, στον ορισμό του υπολογιστικού γράφου και στη συνέχεια στον ορισμό μιας συνεδρίας (session) για την εκτέλεσή του. Tο tf2, όπως συνήθως και η Python, εκτελεί πρόθυμα τον κώδικα και δεν χρειάζεται ξεχωριστός ορισμός συνεδριών: ο γράφος και η συνεδρία αποτελούν στοιχεία μιας ενιαίας υλοποίησης.

Μεταξύ των υπόλοιπων νέων χαρακτηριστικών και διαφορών του tf2 σε σχέση με το tf1 που μπορούμε να ξεχωρίσουμε είναι: 
- η **απλοποίηση της διοχέτευσης (pipeline)** των δεδομένων. Με το tf.data του tf2 μπορούμε να έχουμε απευθείας πρόσβαση σε σύνολα δεδομένων αλλά και να εκτελούμε μετασχηματισμούς με απλό τρόπο. Επίσης, σε αντίθεση με το tf1, δεν απαιτείται καθόλου η δήλωση συμβόλων αντικατάστασης (placeholders) στον ορισμό του γράφου τα οποία στη συνέχεια θα χρησιμοποιηθούν για την εισαγωγή των δεδομένων στο δίκτυο.
- η **απαλοιφή καθολικών μεταβλητών**. Το tf1 βασίζονταν σε μεγάλο βαθμό σε καθολικές μεταβλητές οι οποίες ήταν προσπελάσιμες μόνο από το όνομά τους, το οποίο όμως δεν είναι πάντα γνωστό εφόσον πολύ συχνά έχει οριστεί από άλλους. Σο tf2 ο χρήστης καλείται να παρακολουθεί τις μη καθολικές μεταβλητές του ο ίδιος με τη βοήθεια αντικειμένων του Keras, χωρίς να χρειάζεται πλέον η καθολική υποδομή γύρω από τις μεταβλητές.
- η **εγκαθίδρυση του SavedModel** format (of TensorFlow 2) ως ενιαίο τρόπο αποθήκευσης, φόρτωσης και ανταλλαγής μοντέλων στα TensorFlow, TensorFlow Serving, TensorFlow Lite, TensorFlow.js, TensorFlow Hub κλπ.

Περισσότερα: [Effective TensorFlow 2](https://www.tensorflow.org/guide/effective_tf2), [Overview of changes TensorFlow 1.0 vs TensorFlow 2.0](https://www.datasciencecentral.com/profiles/blogs/tensorflow-1-x-vs-2-x-summary-of-changes)

# Σύνολο δεδομένων CIFAR-100
![alt text](https://datarepository.wolframcloud.com/resources/images/69f/69f1e629-81e6-4eaa-998f-f6734fcd2cb3-io-4-o.en.gif)

To [CIFAR-100](https://www.cs.toronto.edu/~kriz/cifar.html) όπως και το CIFAR-10 είναι επισημειωμένα υποσύνολα του συνόλου δεδομένων “80 million tiny images”. Τα συνέλλεξαν οι Alex Krizhevsky (πρώτος συγγραφέας του [AlexNet - 2012](https://papers.nips.cc/paper/4824-imagenet-classification-with-deep-convolutional-neural-networks.pdf)), Vinod Nair (πρώτος συγγραφέας των [ReLU - 2010](https://www.cs.toronto.edu/~hinton/absps/reluICML.pdf)) και ο Geoffrey Hinton.

Το CIFAR-100 αποτελείται από **60000 έγχρωμες εικόνες των 32x32 pixel χωρισμένες σε 100 κατηγορίες**. Σε κάθε κατηγορία αντιστοιχούν 500 εικόνες εκπαίδευσης και 100 εικόνες ελέγχου, δηλαδή το train-test split είναι προκαθορισμένο. **Κάθε μια από τις 100 κατηγορίες του CIFAR-100 ανήκει και σε μια από 20 υπερκατηγορίες**, για παράδειγμα οι κατηγορίες “maple”, “oak”, “palm”, “pine” και “willow” ανήκουν στην υπερκατηγορία “trees”. Κάθε εικόνα έχει δύο ετικέτες, μια “fine” που δείχνει την κατηγορία της και μια “coarse” που δείχνει την υπερκατηγορία της. **Θα δουλέψουμε αποκλειστικά με τις κατηγορίες ("fine")**.

**To CIFAR-100 είναι, όπως είναι αναμενόμενο, σημαντικά πιο δύσκολο dataset από το CIFAR-10.** Μέχρι το 2019, η απόδοση των συστημάτων state-of-the-art στο CIFAR-10 ήταν ορθότητα (accuracy) [99.00%](https://benchmarks.ai/cifar-10https://) (GPipe: Efficient Training of Giant Neural Networks using Pipeline Parallelism) ενώ στο CIFAR-100 ήταν [91.70%](https://benchmarks.ai/cifar-100https://)
(EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks)

# Προαπαιτούμενα της python3

Θα χρειαστούμε την νεότερη έκδοση του pip και του tensorflow.
"""

!pip install --upgrade pip
!pip install --upgrade tensorflow
!pip install h5py
!pip install git+https://github.com/keras-team/keras.git

"""Κάνουμε τα απαραίτητα import που θα χρησιμοποιήσουμε καθόλη την διάρκεια της μελέτης μας."""

# Commented out IPython magic to ensure Python compatibility.
try:
  # %tensorflow_version only exists in Colab.
#   %tensorflow_version 2.x
except Exception:
  pass

from __future__ import absolute_import, division, print_function, unicode_literals # legacy compatibility

import tensorflow as tf
from tensorflow.keras import datasets, layers, models

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt

"""Τσεκάρουμε να δούμε αν έχουμε την 2.1.0 version του tensorflow."""

tf.__version__

"""# Αρχικές μη βελτιστοποιημένες αρχιτεκτονικές

## Εισαγωγή και επισκόπηση του συνόλου δεδομένων

Παρακάτω, υλοποιούμε ορισμένες χρήσιμες συναρτήσεις που θα χρησιμοποιήσουμε αργότερα στην μελέτη μας.
"""

# helper functions

def select_from_list(from_list, index_list):
    # select from from_list elements with index in index_list
    '''
        from_list:  list
        index_list: list
    '''

    filtered_list = [from_list[i] for i in index_list]
    return(filtered_list)


def get_ds_index(unfiliterd_list, target_list):
    # append in filtered_list the index of each element of unfilterd_list if it exists in in target_list
    '''
        unfiliterd_list:    list
        target_list:        list
    '''

    index = 0
    filtered_list = []
    for i_ in unfiliterd_list:
        if i_[0] in target_list:
            filtered_list.append(index)
        index += 1

    return(filtered_list)


def select_classes_number(classes_number=20):
    # select a url for a unique subset of CIFAR-100 with 20, 40, 60, or 80 classes
    '''
        classes_number:     int 
    '''

    cifar100_20_classes_url = "https://pastebin.com/raw/nzE1n98V"
    cifar100_40_classes_url = "https://pastebin.com/raw/zGX4mCNP"
    cifar100_60_classes_url = "https://pastebin.com/raw/nsDTd3Qn"
    cifar100_80_classes_url = "https://pastebin.com/raw/SNbXz700"
    if classes_number == 20:
        return cifar100_20_classes_url
    elif classes_number == 40:
        return cifar100_40_classes_url
    elif classes_number == 60:
        return cifar100_60_classes_url
    elif classes_number == 80:
        return cifar100_80_classes_url
    else:
        # Not found such url
        return -1

# load the entire dataset
(x_train_all, y_train_all), (x_test_all, y_test_all) = tf.keras.datasets.cifar100.load_data(label_mode='fine')

x_train_all.shape

"""Η κάθε ομάδα θα δουλέψει με 
Στο επόμενο κελί, αντικαταστήστε την τιμή της μεταβλητής `team_seed` με τον αριθμό που αντιστοιχεί στην ομάδας σας σε [αυτό το σύνδεσμο](https://docs.google.com/spreadsheets/d/1oEr3yuPg22lmMeqDjFtWjJRzmGQ8N57YIuV-ZOvy3dM/edit?usp=sharing).
"""

# REPLACE WITH YOUR TEAM NUMBER -- ΜΑ7
team_seed = 7

"""Στο επόμενο κελί διαλέγουμε το πλήθος των κατηγορίων μας: 20 (default), 40, 60 ή 80."""

# select the number of classes
cifar100_classes_url = select_classes_number(20)

"""Δημιουργούμε το μοναδικό dataset της ομάδας μας:"""

team_classes = pd.read_csv(cifar100_classes_url, sep=',', header=None)
CIFAR100_LABELS_LIST = pd.read_csv('https://pastebin.com/raw/qgDaNggt', sep=',', header=None).astype(str).values.tolist()[0]

our_index = team_classes.iloc[team_seed,:].values.tolist()
our_classes = select_from_list(CIFAR100_LABELS_LIST, our_index)
train_index = get_ds_index(y_train_all, our_index)
test_index = get_ds_index(y_test_all, our_index)

x_train_ds = np.asarray(select_from_list(x_train_all, train_index))
y_train_ds = np.asarray(select_from_list(y_train_all, train_index))
x_test_ds = np.asarray(select_from_list(x_test_all, test_index))
y_test_ds = np.asarray(select_from_list(y_test_all, test_index))

"""Δημιουργούμε το train, validation και test set που θα χρησιμοποιήσουμε στην μελέτη μας με το validation να είναι το 15% του training set. Αφού πάρουμε τα παραπάνω σύνολα, τα κανονικοποιούμε.

Παρακάτω, αναπαριστούμε τις πρώτες 9 εικόνες του training set με τις αντίστοιχες ετικέτες τους.
"""

# get (train) dataset dimensions
data_size, img_rows, img_cols, img_channels = x_train_ds.shape

# set validation set percentage (wrt the training set size)
validation_percentage = 0.15
val_size = round(validation_percentage * data_size)

# Reserve val_size samples for validation and normalize all values
X_val = x_train_ds[-val_size:] / 255
y_val = y_train_ds[-val_size:]
X_train = x_train_ds[:-val_size] / 255
y_train = y_train_ds[:-val_size]
X_test = x_test_ds / 255
y_test = y_test_ds

# summarize loaded dataset
print('Train: X=%s, y=%s' % (X_train.shape, y_train.shape))
print('Validation: X=%s, y=%s' % (X_val.shape, y_val.shape))
print('Test: X=%s, y=%s' % (X_test.shape, y_test.shape))


def class_label_from_index(fine_category):
    # get class label from class index
    return(CIFAR100_LABELS_LIST[fine_category.item(0)])

# plot first few images
plt.figure(figsize=(6, 6))
for i in range(9):
	# define subplot
    plt.subplot(330 + 1 + i).set_title(class_label_from_index(y_train[i]))
    # plot raw pixel data
    plt.imshow(X_train[i], cmap=plt.get_cmap('gray'))
    
#show the figure
plt.show()

"""Επείδη οι συνολικές μας κατηγορίες είναι 20 μετατρέπουμε τα labels των train, val, test σε labels από το 0 έως το 19, προκειμένου αργότερα το output layer των νευρωνικών μας δικτύων να έχει 20 νευρώνες αντί για 100."""

# find unique labels using a dict -- key: real label, value: transformed label
labels = {}
for i,label in enumerate(np.unique(y_train)):
    labels[label] = i

print(labels)

# transform y sets
y_train = [labels[int(label)] for label in y_train]
y_val = [labels[int(label)] for label in y_val]
y_test = [labels[int(label)] for label in y_test]

"""## Συναρτήσεις εκπαίδευσης

Θα χρησιμοποιήσουμε την ιδιότητα data prefetch του tf2:
"""

# we use prefetch https://www.tensorflow.org/api_docs/python/tf/data/Dataset#prefetch 
# see also AUTOTUNE
# the dataset is now "infinite"

BATCH_SIZE = 128
AUTOTUNE = tf.data.experimental.AUTOTUNE # https://www.tensorflow.org/guide/data_performance

def _input_fn(x, y, BATCH_SIZE, reshuffle_each_iteration=None, repeat=False):
    # Creates a PrefetchDataset object
    ds = tf.data.Dataset.from_tensor_slices((x,y))
    ds = ds.shuffle(buffer_size=data_size, reshuffle_each_iteration=reshuffle_each_iteration)
    if repeat:
        ds = ds.repeat()  # infinite iterations
    ds = ds.batch(BATCH_SIZE)
    ds = ds.prefetch(buffer_size=AUTOTUNE)
    return ds

train_ds =_input_fn(X_train, y_train, BATCH_SIZE, reshuffle_each_iteration=True, repeat=True)
validation_ds =_input_fn(X_val, y_val, BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 
test_ds =_input_fn(X_test, y_test, BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 

# steps_per_epoch and validation_steps for training and validation: 
# https://www.tensorflow.org/guide/keras/train_and_evaluate
def train_model(model, epochs=50, steps_per_epoch=None, validation_steps=None):
    history = model.fit(
        train_ds, epochs=epochs, steps_per_epoch=steps_per_epoch, 
        validation_data=validation_ds, validation_steps=validation_steps
    )
    return(history)

"""## Γραφικές παραστάσεις εκπαίδευσης και απόδοση στο σύνολο ελέγχου"""

# plot diagnostic learning curves
def summarize_diagnostics(history):
	plt.figure(figsize=(8, 8))
	plt.suptitle('Training Curves')
	# plot loss
	plt.subplot(211)
	plt.title('Cross Entropy Loss')
	plt.plot(history.history['loss'], color='blue', label='train')
	plt.plot(history.history['val_loss'], color='orange', label='val')
	plt.legend(loc='upper right')
	# plot accuracy
	plt.subplot(212)
	plt.title('Classification Accuracy')
	plt.plot(history.history['accuracy'], color='blue', label='train')
	plt.plot(history.history['val_accuracy'], color='orange', label='val')
	plt.legend(loc='lower right')
	return plt
 

def model_evaluation(model, evaluation_steps):
	# print test set evaluation metrics
	print('\nTest set evaluation metrics')
	loss0, accuracy0 = model.evaluate(test_ds, steps=evaluation_steps)
	print("loss: {:.2f}".format(loss0))
	print("accuracy: {:.2f}".format(accuracy0))


def model_report(model, history, evaluation_steps=None):
	plt = summarize_diagnostics(history)
	plt.show()
	model_evaluation(model, evaluation_steps)

"""## Μοντέλα δικτύων

### Ένα μικρό συνελικτικό δίκτυο "from scratch"

Αρχικά, δημιουργούμε ενά απλό CNN με 3 convolutional layers (όπου το καθένα αποτελείται από Conv2D και MaxPooling), 1 flatten layer (που μας βοηθάει να κάνουμε flatten τις διαστάσεις και 1 fully-connected με Dropout, για αποφυγή του overfitting. Η συνάρτηση ενεργοποιήσης του τελευταίου είναι η softmax και η loss function είναι η cross entropy, προκειμένου να γίνει ταξινόμηση στις 20 πιθανές κατηγορίες. (μέθοδος όμοια με το logistic regression του κλασικού machine learning)
"""

from tensorflow.keras import optimizers

def init_simple_model(summary=True):
    # 3-layer CNN and 1-layer fc
    model = models.Sequential()
    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Conv2D(64, (3, 3), activation='relu'))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Flatten())
    model.add(layers.Dropout(0.35))
    model.add(layers.Dense(20, activation='softmax'))

    model.compile(optimizer=optimizers.Adam(learning_rate=0.001), loss=tf.keras.losses.sparse_categorical_crossentropy, 
                  metrics=["accuracy"])
    if summary: 
        model.summary()
    return model

SIMPLE_MODEL = init_simple_model(summary=True)
SIMPLE_MODEL_history = train_model(SIMPLE_MODEL, epochs=60, 
                                   steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), validation_steps=None)

model_report(SIMPLE_MODEL, SIMPLE_MODEL_history, None)

"""### Μεταφορά μάθησης: VGG16

Αφού είδαμε την χαμηλή επίδοση του παραπάνω μοντέλου, θα χρησιμοποιήσουμε transfer learning, προκειμένου να δούμε αυτή τη φορά καλύτερα αποτελέσματα. Πιο αναλυτικά, θα γίνει χρήση του VGG16 που έχει προεκπαιδευμένα βάρη και θα του προσθέσουμε dropout, GlobalAveragePooling2D και ένα fully-connected. Ορίζουμε την μεταβλητή trainable=True, προκειμένου να εκπαιδεύσουμε όλα τα βάρη, εκπαιδευμένα και μη.
"""

# transfer learning: VGG16 trained on ImageNet without the top layer

def init_VGG16_model(summary):
    VGG16_MODEL=tf.keras.applications.VGG16(input_shape=(img_rows, img_cols, img_channels), include_top=False, weights='imagenet')

    # unfreeze conv layers
    VGG16_MODEL.trainable=True

    dropout_layer = tf.keras.layers.Dropout(rate = 0.5)
    global_average_layer = tf.keras.layers.GlobalAveragePooling2D()

    # add top layer for CIFAR100 classification
    prediction_layer = tf.keras.layers.Dense(20,activation='softmax')
    model = tf.keras.Sequential([VGG16_MODEL, dropout_layer, global_average_layer, prediction_layer])
    model.compile(optimizer=tf.optimizers.Adam(learning_rate=0.00005), loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    if summary: 
        model.summary()
    return model

VGG16_MODEL = init_VGG16_model(summary=True)
VGG16_MODEL_history = train_model(VGG16_MODEL, epochs=25, 
                                  steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), validation_steps=None)

model_report(VGG16_MODEL, VGG16_MODEL_history, None)

"""### Αποτελέσματα

Βλέπουμε πως με χρήση transfer learning, πετυχαίνουμε πολύ καλύτερη επίδοση, από ότι στο "from scratch", της τάξης του 21% πάνω.  
Ωστόσο, μπορούμε να πετύχουμε αρκετά καλύτερες επιδόσεις και στους δύο τύπους αρχιτεκτονικών και με αύτο το κομμάτι θα ασχοληθούμε από εδώ και στο εξής στην μελέτη μας.

# Βελτίωση της επίδοσης με πειράματα

Καλούμαστε, λοιπόν, να βελτιώσουμε τα αποτελέσματα ταξινόμησης στο CIFAR-100 και να βγάλουμε στο τέλος τα αντίστοιχα συμπεράσματα.

## Δοκιμές διαφορετικών μοντέλων

Στο σημείο αυτό θα βελτιστοποιήσουμε μοντέλα "from scratch", καθώς και μοντέλα με μεταφορά μάθησης (transfer learning).

### Μοντέλα "from scratch"

Λαμβάνουμε υπόψιν τα εξής: 
- τη [βιβλιογραφία απο το leaderboard του CIFAR-100](https://benchmarks.ai/cifar-100) για αρχιτεκτονικές και παραμέτρους των δικτύων,
- την [από σχετική αναζήτηση στο Google Scholar](https://scholar.google.gr/scholar?hl=en&as_sdt=0%2C5&q=cifar+100+cnn&oq=cifa)
"""

AUTOTUNE = tf.data.experimental.AUTOTUNE # https://www.tensorflow.org/guide/data_performance

def _input_fn(x, y, batch_size, reshuffle_each_iteration=None, repeat=False):
    # Creates a PrefetchDataset object
    '''
        x:                          numpy Array
        y:                          numpy Array
        batch_size:                 int
        reshuffle_each_iteration:   Boolean
        repeat:                     Boolean
    '''

    ds = tf.data.Dataset.from_tensor_slices((x,y))
    ds = ds.shuffle(buffer_size=data_size, reshuffle_each_iteration=reshuffle_each_iteration)
    if repeat:
        ds = ds.repeat()  # infinite iterations
    ds = ds.batch(batch_size)
    ds = ds.prefetch(buffer_size=AUTOTUNE)
    return ds 


def train_model(model, callbacks, epochs=50, steps_per_epoch=None, validation_steps=None):
    # Training the given model and returns its learning history
    history = model.fit(
        train_ds, epochs=epochs, steps_per_epoch=steps_per_epoch, 
        validation_data=validation_ds, validation_steps=validation_steps,
        callbacks=callbacks
    )
    return(history)

"""#### CNN4

##### Αρχιτεκτονική CNN

Θα χρησιμοποιήσουμε ένα δίκτυο που θα αποτελείται από 4 Convolutional layers (το καθένα περιέχει Conv2D, BatchNormalization, MaxPooling, Dropout) και 1 fully-connected layer. Χρησιμοποιούμε ακόμα σε κάθε layer ως weight decay την l1 norm με λ=0.001, ενώ ως optimizer του συστήματος παίρνουμε τον Adam (lr=0.0001) και σαν Loss function την cross-entropy, συνδυασμένη με softmax στο output layer, όπως έγινε και παραπάνω.
"""

from tensorflow.keras import optimizers
from tensorflow.keras.regularizers import l1

def CNN4(summary=True):
    # 4-Convolutiona layers and 1-layer fc 
    model = models.Sequential()

    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), 
                            kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.2))

    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.2))

    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.Dropout(0.2))

    model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.MaxPooling2D((2, 2)))

    model.add(layers.Flatten())

    model.add(layers.Dropout(0.35))
    model.add(layers.Dense(20, activation='softmax', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))

    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), 
                  loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    
    if summary: 
        model.summary()

    return model

"""##### Φάση εκπαίδευσης

Το αρχικό μας "from scratch" μοντέλο, ήταν ήδη κάπως βελτιστοποιημένο σε σχέση με της εκφώνησης, δεδομένου ότι περιείχε 1 fully-connected layer (αντί για 2) και dropout πριν την έξοδο, με αποτέλεσμα να συρρίκνωνε αρκετά το overfitting.   

Με σκοπό να αυξήσουμε την επίδοση, πειραματιστήκαμε με αρκετούς τρόπους. Αρχικά προσθέσαμε ενα Conv2D ακόμα, έχοντας μόνο το τελικό dropout, και το test score ήταν γύρω στο 67%.  Στην συνέχεια προσθέσαμε ένα ακόμα fully-connected και παρατηρήσαμε overfitting. Βάλαμε παντού χαμηλά ποσοστά dropout και batch normalization και είδαμε πως για το lr=0.001 έκανε ταλαντώσεις το loss, και για αυτό το λόγο το μειώσαμε κατά μία τάξη μεγέθους. Το μοντέλο είδαμε πως συνεχίζει να κάνει overfitting, με αποτέλεσμα να βγάλουμε το fully-connected που προσθέσαμε. Τρέξαμε το μοντέλο και είδαμε test score ίσο περίπου με 69%. Επιπλέον, βάλαμε κι άλλο Conv2D, αλλά δεν είδαμε κάποια σημαντική διαφορά σε σχέση με το να έχουμε συνολικά τέσσερα, και το αφαιρέσαμε. Θελήσαμε να βελτίωσουμε το μοντέλο αυτό με αλλαγές ως προς learning rate, validation checkpoint, optimizer, dropout, batch_size και weight decay.
"""

BATCH_SIZE = 150

# Creating PrefetchDataset objects
train_ds =_input_fn(X_train, y_train, batch_size=BATCH_SIZE, reshuffle_each_iteration=True, repeat=True)
validation_ds =_input_fn(X_val, y_val, batch_size=BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 
test_ds =_input_fn(X_test, y_test, batch_size=1, reshuffle_each_iteration=False, repeat=False)

# Training
cnn = CNN4(summary=True)

# Checkpoint
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy')

cnn_history = train_model(cnn, epochs=800, 
                          steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), 
                          callbacks=[mc],
                          validation_steps=None)

"""##### Testing"""

from tensorflow.keras.models import load_model
saved_cnn = load_model('best_model.h5')

model_report(saved_cnn, cnn_history, evaluation_steps=None)

"""Αρχικά, αυξήσαμε αρκετά το batch_size και είδαμε πως το μοντέλο μας αργούσε να φθάσει σε σύγκλιση, καθώς γίνονται λιγότερα updates ανά εποχή, με αποτέλεσμα το ορίσαμε 150. Αλλάξαμε τον optimizer σε SGD, και είδαμε πως με αυτό τον τρόπο δεν έφθανε σε σύγκλιση γρήγορα. Αυξήσαμε το learning rate και είδαμε πως το test score δεν βελτιώθηκε. Οπότε, χρησιμοποιήσαμε Adam. Βάζοντας weight decay και σχετικά μεγάλο dropout (0.2-0.35) και με learning rate ίσο με 0.0001 (για μεγαλύτερη τάξη μεγέθους το μοντέλο έκανε ταλαντώσεις τόσο στο train_loss όσο και στο val_loss), στοχεύσαμε το train loss να μειώνεται με όσο το δυνατόν παρόμοιο ρυθμό με το val loss ή να φθήνουν συνεχώς και τα δυο, με αποτελέσμα να αυξήσουμε τις εποχές σε 400 (6.5 λεπτά, μικρός χρόνος training) και να πετύχουμε σκορ πάνω απο 70%, και συγκεκριμένα 73%. Επειδή παρατηρήσαμε πως τα learning curves ήταν φθήνουσες συναρτήσεις και για το train loss και για το val loss, δηλαδή είχαμε undefitting, αυξήσαμε τις εποχές, γνωρίζοντας πως θα ανεβάσουμε και άλλο την επιδοση. Και πράγματι, τρέχοντας στις διπλάσιες επαναλήψεις (800, 12.5 λεπτά εκπαίδευσης), φτάσαμε το test score σε 74% και το validation score έως και 77.5%. Σημειώνουμε πως οι πολλές εποχές δεν παραμονέυουν τον κίνδυνο του overfitting, αφού με την χρήση του checkpoint κρατάμε το καλύτερο βάσει του validation loss. Ακόμα, παίρνοντας υπόψιν στο checkpoint την μεταβλητή val_accuracy αντί του val_loss, αφού είχαμε δει και το 77% στο validation (σκορ που δεν αντιστοιχούσε στο μικρότερο val_loss), καταλήγουμε σε test score ίσο με 75%.  
Αξίζει να σημειωθεί πως η παραπάνω εκπαίδευση δεν αποτελεί περίπτωση overfitting, αφού το val_loss και το train_loss "παγώνουν" στην ίδια εποχή (δηλαδή αρχίζουν και ταλαντώνονται αμφότερα) , μετά την οποία φτάνουν τελικά σε κάποιο ελάχιστο. Τέλος, επισημαίνουμε πως καταφέραμε να φέρουμε το "from scratch" σε απόδοση πολύ κοντινή με την απόδοση του μη βελτιστοποιημένου transfer learning (78%).

#### CNN6

Ομολογουμένως, την προηγούμενη αρχιτεκτονική την φθάσαμε σε ένα αρκέτα καλό σημείο βελτιστοποίησης. Ωστόσο, θα προσπαθήσουμε να ανεβάσουμε την επίδοση μας με την χρήση ενός ακόμα πιο περίπλοκου μοντέλου, που περιέχει 6 Conv2D layers.

##### Αρχιτεκτονική CNN

Θα χρησιμοποιήσουμε ένα δίκτυο που θα αποτελείται από 3 διπλά Convolutional layers (το καθένα περιέχει Conv2D, BatchNormalization, MaxPooling, Dropout) και 1 fully-connected layer. Χρησιμοποιούμε ακόμα σε κάθε layer ως weight decay την l1 norm με λ=0.001, ενώ ως optimizer του συστήματος παίρνουμε τον Adam (lr=0.0001) και σαν Loss function την cross-entropy, συνδυασμένη με softmax στο output layer, όπως έγινε και στο CNN4 παραπάνω.
"""

from tensorflow.keras import optimizers
from tensorflow.keras.regularizers import l1

def CNN6(summary=True):
    # 4-Convolutiona layers and 1-layer fc 
    model = models.Sequential()

    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(32, 32, 3), 
                            kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.25))

    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.MaxPooling2D((2, 2)))
    model.add(layers.Dropout(0.25))

    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.BatchNormalization())
    model.add(layers.Conv2D(256, (3, 3), activation='relu', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))
    model.add(layers.Dropout(0.25))

    model.add(layers.Flatten())

    model.add(layers.Dropout(0.4))
    model.add(layers.Dense(20, activation='softmax', kernel_regularizer=l1(0.001), bias_regularizer=l1(0.001)))

    model.compile(optimizer=optimizers.Adam(learning_rate=0.0001), 
                  loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    
    if summary: 
        model.summary()

    return model

"""##### Φάση εκπαίδευσης

Ουσιαστικά, επεκτείνουμε το CNN4 με την προσθήκη διπλών convolutional layers, ενώ χρησιμοποιούμε ίδιες υπερπαραμέτρους, με εξαίρεση το πλήθος των εποχών που τώρα είναι 300.
"""

BATCH_SIZE = 300

# Creating PrefetchDataset objects
train_ds =_input_fn(X_train, y_train, batch_size=BATCH_SIZE, reshuffle_each_iteration=True, repeat=True)
validation_ds =_input_fn(X_val, y_val, batch_size=BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 
test_ds =_input_fn(X_test, y_test, batch_size=1, reshuffle_each_iteration=False, repeat=False)

# Training
cnn = CNN6(summary=True)

# Checkpoint
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy')

cnn_history = train_model(cnn, epochs=300, 
                          steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), 
                          callbacks=[mc],
                          validation_steps=None)

"""##### Testing"""

from tensorflow.keras.models import load_model
saved_cnn = load_model('best_model.h5')

model_report(saved_cnn, cnn_history, evaluation_steps=None)

"""Παρατηρούμε πως το validation score έφτασε πάνω από 78% σε κάποιες εποχές. Αυτό σημαίνει πως για τέτοιο score περιμέναμε και το test score να είναι όμοιο του. Ωστόσο, το test score βγήκε 74%, λόγω τυχαιότητας. Αν είχε επιλεχτεί κάποιο άλλο model στο training με val_accuracy παρόμοιο της μέγιστης ενδεχομένως να είχαμε κοντά στο 77% test score. Βλέπουμε πως και σε αυτήν την περίπτωση είμαστε σε ίδια επίπεδα με το VGG16 που είδαμε παραπάνω. Παρατηρούμε ακόμα πως ούτε εδώ έχουμε περίπτωση overfitting, και πως ο χρόνος εκπαίδευσης ήταν πάλι στα 12.5 λεπτά, γεγονός που συνέβαλε και ο διπλασιασμός του batch size.

### Transfer Learning

#### Εκπαίδευση βαρών

Ταυτόχρονα με την αρχιτεκτονική, στη μεταφορά μάθησης εισάγουμε και τη γνώση που έχει αποκτήσει το μοντέλο, δηλαδή τις τιμές των βαρών του όπως έχουν προκύψει μετά από εκπαίδευση συνήθως στο (τεράστιο) ImageNet. Οταν εισάγουμε ένα μοντέλο με μεταφορά μάθησης έχουμε τρεις επιλογές για την εκπαίδευση:
- να παγώσουμε τη συνελικτική βάση και να εκπαιδεύσουμε την κεφαλή ταξινόμησης (classification head). Αυτό αντιστοιχεί στο να χρησιμοποιήσουμε τη συνελικτική βάση για εξαγωγή χαρακτηριστικών (feature extraction), σημαία trainable=False.
- να συνεχίσουμε να εκπαιδεύουμε όλα τα επίπεδα του δικτύου, σημαία trainable=True.
- να εκπαιδευτεί μόνο ένα ποσοστό των επιπέδων, εβρισκόμενο προς την έξοδο του δικτύου. Οι σημαίες trainable εδώ θα πρέπει να οριστούν ανά επίπεδο.   

Ωστόσο, στην μελέτη μας όταν παγώνουμε κάποια layers, το σύστημα δεν αποδίδει το ίδιο καλά με όταν είναι όλα trainable. Οπότε, θα δείξουμε μόνο την βέλτιστη περίπτωση.

#### Διαθέσιμα μοντέλα για μεταφορά μάθησης στο tf2

Μέσω tf.keras.applications που παρέχει προεκπαιδευμένα μοντέλα από το Keras και συγκεκριμένα τα δίκτυα: DenseNet, Inception-ResNet V2, Inception V3, MobileNet v1, MobileNet v2, NASNet-A, ResNet, ResNet v2, VGG16, VGG19 και Xception V1.

Στην μελέτη μας, χρησιμοποιήσαμε το VGG16 και το VGG19. Επειδή είδαμε πως το VGG16 έδινε μονίμως καλύτερες επιδόσεις για τις ίδιες παραμέτρους, θα παρουσιάσουμε μόνο αυτό.

#### VGG16 - Data augmentation

Συμφώνα το [paper](https://scholar.smu.edu/cgi/viewcontent.cgi?article=1091&context=datasciencereview), το VGG16 αποδίδει αρκετά καλύτερα στο CIFAR-10, όταν γίνεται χρήση του data augmentation. Μάλιστα, η βελτίωση του επίδοσης με κατάλληλο fine tuning έφτασε σε ποσοστό 8%. Πράγματι, και στην μελέτη μας, δουλεύοντας στο δεδομένο dataset του CIFAR-100, η επίδοση του συστήματος χωρίς data augmentation αλλά με dropout, batch normalization και fine tuning έφτανε κοντά στο αρχικό transfer learning δίκτυο, που δείξαμε παραπάνω, δηλαδή στο 79%, έχοντας, ωστόσο, λιγότερο overfitting, αφού το συνολικό loss από 1.23 μειώθηκε στο 0.91. Παρακάτω, παρουσιάζουμε το τελικό μας VGG16 δίκτυο που παρουσιάζει την βέλτιστη επίδοση σε test accuracy.

##### Αρχιτεκτονική VGG16

Η αρχιτεκτονική που θα χρησιμοποιήσουμε είναι το VGG16 δίκτυο, ακολουθούμενο από Flatten, ένα fully-connected(512) και ένα output fully-connected(20). Πριν το output layer χρησιμοποιούμε ακόμα ένα dropout(0.15), προκειμένου να περιορίσουμε κάπως το αρχικό overfitting. Αξίζει να σημειώθεί πως χρησιμοποιούμε την elu έναντι της relu ως activation function του fully-connected(512), καθώς σημειώσαμε καλύτερη επίδοση με την χρήση αυτής.
"""

from tensorflow.keras import optimizers, layers
from tensorflow.keras.regularizers import l1

def VGG16(summary=True):
    # transfer learning: VGG16 trained on ImageNet without the top layer
    model = tf.keras.Sequential()

    # VGG16
    vgg = tf.keras.applications.VGG16(input_shape=(img_rows, img_cols, img_channels), 
                                                   include_top=False, weights='imagenet')

    model.add(vgg)
    # unfreeze VGG layers
    model.trainable=True

    model.add(layers.Flatten())
    model.add( layers.Dense(512, activation='elu') )
    model.add( layers.Dropout(rate = 0.15) )

    # Fully-connected output layer
    model.add( layers.Dense(20, activation='softmax') )

    # # choose the layers which are updated by training
    # layer_num = len(model.layers)
    # for layer in model.layers[:10]:
    #     layer.trainable = False

    model.compile(optimizer=optimizers.Adam(lr=0.00008), 
                  loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    if summary: 
        model.summary()
        
    return model

"""##### Φάση Εκπαίδευσης

Χρησιμοποιούμε data augmentation, προκειμένου να αυξήσουμε τα δεδομένα μας και κάθε φορά το μοντέλο να συναντά νέες εικόνες, οι οποίες προέρχονται από τους παρακάτω μετασχηματισμούς: rotation, width shift, height shift, horizontal flip.   
Τα ποσοστά που ακολουθούν στην υλοποίηση μας, προέρχονται από την εξαγωγή αρκετών επιδόσεων διαφορετικών δοκιμών. Το γεγονός πως το μοντέλο βλέπει κάθε φορά νέα εικόνα οδήγει στην μείωση του overfitting, αφού το dataset συνεχώς αλλάζει.
"""

# Data augmentation
from keras.preprocessing.image import ImageDataGenerator

image_gen_train = ImageDataGenerator(
                        rotation_range=17,
                        width_shift_range=.11,
                        height_shift_range=.11,
                        horizontal_flip=True,
                    )

BATCH_SIZE = 250

# Creating PrefetchDataset objects
train_ds =_input_fn(X_train, y_train, batch_size=BATCH_SIZE, reshuffle_each_iteration=True, repeat=True)
validation_ds =_input_fn(X_val, y_val, batch_size=BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 
test_ds =_input_fn(X_test, y_test, batch_size=1, reshuffle_each_iteration=False, repeat=False)

"""Χρησιμοποιούμε πάλι το checkpoint, προκειμένου να πάρουμε το μοντελό εκείνης της εποχής που έχει σημειωθεί το μικρότερο val_loss."""

# Training
model = VGG16(summary=True)

# Data augmentation
image_gen_train.fit(X_train)
train_ds = image_gen_train.flow(x=X_train,
                                y=y_train,
                                batch_size=BATCH_SIZE,
                                shuffle=True)

# Checkpoint
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('best_model.h5', monitor='val_loss')

model_history = train_model(model, epochs=40, 
                            steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), 
                            callbacks=[mc],
                            validation_steps=None)

"""##### Testing"""

from tensorflow.keras.models import load_model
saved_model = load_model('best_model.h5')

model_report(saved_model, model_history, evaluation_steps=None)

"""Βλέπουμε πως το παραπάνω μοντέλο καταφέρνει να ανεβάσει αρκετά ψηλά την επίδοση στο test set, φτάνοντας το 83%, ενώ κατεβάζει βέλτιστα σε σχέση με τα παραπάνω μοντέλα και το loss (0.84). Ακομά καταφέρνουμε να μειώσουμε πάρα πολύ και τον χρόνο εκπαίδευσης στα 5 λεπτά, σημειώνοντας βέλτιστη επίδοση σε σχέση με τις υπόλοιπες προσπάθειες βελτιστοποίησης. Σημειώνουμε πως παρόμοια αποτελέσματα δίνει και η χρήση του Adamax optimizer αντί του Adam στο ίδιο πλήθος εποχών.

#### VGG16(s) - TFRecords - Data Augmentation

Αν και ουσιαστικά δεν χρειάζεται να βελτιστοποιήσουμε ως προς την μνήμη, αφού έχουμε πολύ μικρή κατανάλωση RAM με ένα τόσο σχετικά  μικρό σύνολο δεδομένων, για λόγους μελέτης θα υλοποιήσουμε και ένα δίκτυο, ίδιας αρχιτεκτονικής με το VGG16, το οποίο θα χρησιμοποιεί τόσο prefetching, όπως και τα υπόλοιπα που είδαμε έως τώρα, όσο και σειριοποίηση των δεδομένων μαζί με data augmentation.  Στόχος μας είναι να εξετάσουμε κατά πόσο αυτή η τεχνική τελικά οφελεί στον συνολικό χρόνο εκπαίδευσης και μνήμης.
"""

import sys

def print_progress(count, total):
    # Percentage completion.
    pct_complete = float(count) / total

    # Status-message.
    # Note the \r which means the line should overwrite itself.
    msg = "\r- Progress: {0:.1%}".format(pct_complete)

    # Print it.
    sys.stdout.write(msg)
    sys.stdout.flush()
    return


def wrap_int64(value):
    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))
    

def _bytes_feature(value):
    """Returns a bytes_list from a string / byte."""
    # If the value is an eager tensor BytesList won't unpack a string from an EagerTensor.
    if isinstance(value, type(tf.constant(0))):
        value = value.numpy() 
    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))

"""##### Data Augmentation

Χρησιμοποιούμε το ίδιο data augmentation με το προηγούμενο μας μοντέλο.
"""

# Data augmentation
from keras.preprocessing.image import ImageDataGenerator

image_gen_train = ImageDataGenerator(
                        rotation_range=17,
                        width_shift_range=.11,
                        height_shift_range=.11,
                        horizontal_flip=True,
                    )

"""##### Παραλληλοποίηση των δεδομένων

Δημιουργούμε αρχικά τα TFRecords από τις εικόνες που είναι ήδη σε μορφή numpy arrays.
"""

from matplotlib.image import imread

def convert(X, y, train, out_path):
    '''
        X:          numpy array
        y:          numpy array
        train:      Boolean, if True then Data Augmentation
        out_path:   File-path for the TFRecords output file.
    '''

    print("Converting: " + out_path)
    
    # Number of images. Used when printing the progress.
    num_images = len(X)
    
    # Data Augmentation
    if train:
        image_gen_train.fit(X)

    # Open a TFRecordWriter for the output-file.
    with tf.io.TFRecordWriter(out_path) as writer:
        
        # Iterate over all the image-paths and class-labels.
        for i, (img, label) in enumerate(zip(X, y)):
            # Print the percentage-progress.
            print_progress(count=i, total=num_images-1)

            # Convert the image to raw bytes.
            img_bytes = tf.io.serialize_tensor(img)

            # Create a dict with the data we want to save in the
            # TFRecords file. You can add more relevant data here.
            data = \
                {
                    'image': _bytes_feature(img_bytes),
                    'label': wrap_int64(label)
                }

            # Wrap the data as TensorFlow Features.
            feature = tf.train.Features(feature=data)

            # Wrap again as a TensorFlow Example.
            example = tf.train.Example(features=feature)

            # Serialize the data.
            serialized = example.SerializeToString()
            
            # Write the serialized data to the TFRecords file.
            writer.write(serialized)

        return

path_tfrecords_train = 'train.tfrecords'
path_tfrecords_val = 'val.tfrecords'
path_tfrecords_test = 'test.tfrecords'

convert(X=X_train,
        y=y_train,
        train=True,
        out_path=path_tfrecords_train)

convert(X=X_val,
        y=y_val,
        train=False,
        out_path=path_tfrecords_val)

convert(X=X_test,
        y=y_test,
        train=False,
        out_path=path_tfrecords_test)

def parse(serialized):
    # Define a dict with the data-names and types we expect to
    # find in the TFRecords file.
    # It is a bit awkward that this needs to be specified again,
    # because it could have been written in the header of the
    # TFRecords file instead.
    features = {
        'image': tf.io.FixedLenFeature((), tf.string),
        'label': tf.io.FixedLenFeature((), tf.int64)
    }

    example = tf.io.parse_single_example(serialized, features)
    
    image = tf.io.parse_tensor(example['image'], out_type=tf.float64)

    # Image Shape (32,32,3)
    image = tf.reshape(image, [32,32,3])
    
    return image, example['label']

def input_fn(filenames, train, batch_size=250, buffer_size=512):
    '''
        filenames:      Filenames for the TFRecords files.
        train:          Boolean whether training (True) or testing (False).
        batch_size:     Return batches of this size.
        buffer_size:    Read buffers of this size. The random shuffling
                        is done on the buffer, so it must be big enough.
    '''

    # Create a TensorFlow Dataset-object which has functionality
    # for reading and shuffling data from TFRecords files.
    dataset = tf.data.TFRecordDataset(filenames=filenames)

    # Parse the serialized data in the TFRecords files.
    # This returns TensorFlow tensors for the image and labels.
    dataset = dataset.map(parse)
    print(dataset)

    if train:
        # If training then read a buffer of the given size and
        # randomly shuffle it.
        dataset = dataset.shuffle(buffer_size=buffer_size)

        # Allow infinite reading of the data.
        num_repeat = None
    else:
        # If testing then don't shuffle the data.
        
        # Only go through the data once.
        num_repeat = 1

    # Repeat the dataset the given number of times.
    dataset = dataset.repeat(num_repeat)
    
    # Get a batch of data with the given size.
    dataset = dataset.batch(batch_size)

    # Prefetching
    dataset = dataset.prefetch(buffer_size=AUTOTUNE)

    return dataset

"""##### Αρχιτεκτονική VGG16(s)

Η αρχιτεκτονική που θα χρησιμοποιήσουμε είναι το VGG16 δίκτυο, ακολουθούμενο από Flatten, ένα fully-connected(512) και ένα output fully-connected(20). Πριν το output layer χρησιμοποιούμε ακόμα ένα dropout(0.15), προκειμένου να περιορίσουμε κάπως το αρχικό overfitting. Αξίζει να σημειώθεί πως χρησιμοποιούμε την elu έναντι της relu ως activation function του fully-connected(512), καθώς σημειώσαμε καλύτερη επίδοση με την χρήση αυτής. Δηλαδή είναι το ίδιο ακριβώς με το παραπάνω.
"""

from tensorflow.keras import optimizers, layers
from tensorflow.keras.regularizers import l1

def VGG16(summary=True):
    # transfer learning: VGG16 trained on ImageNet without the top layer
    model = tf.keras.Sequential()

    # VGG16
    vgg = tf.keras.applications.VGG16(input_shape=(img_rows, img_cols, img_channels), 
                                                   include_top=False, weights='imagenet')

    model.add(vgg)
    # unfreeze VGG layers
    model.trainable=True

    model.add(layers.Flatten())
    model.add( layers.Dense(512, activation='elu') )
    model.add( layers.Dropout(rate = 0.15) )

    # Fully-connected output layer
    model.add( layers.Dense(20, activation='softmax') )

    model.compile(optimizer=optimizers.Adam(lr=0.00008), 
                  loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    if summary: 
        model.summary()
        
    return model

"""##### Φάση Εκπαίδευσης"""

BATCH_SIZE = 250

# Creating PrefetchDataset objects
train_ds = input_fn(path_tfrecords_train, train=True, batch_size=BATCH_SIZE)
validation_ds = input_fn(path_tfrecords_val, train=False, batch_size=BATCH_SIZE) 
test_ds = input_fn(path_tfrecords_test, train=False, batch_size=BATCH_SIZE)

"""Χρησιμοποιούμε πάλι το checkpoint, προκειμένου να πάρουμε το μοντελό εκείνης της εποχής που έχει σημειωθεί το μικρότερο val_loss."""

# Training
model = VGG16(summary=True)

# # Data augmentation
train_ds = image_gen_train.flow(x=X_train,
                                y=y_train,
                                batch_size=BATCH_SIZE,
                                shuffle=True)

# Checkpoint
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('best_model.h5', monitor='val_loss')

model_history = train_model(model, epochs=40, 
                            steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), 
                            callbacks=[mc],
                            validation_steps=None)

"""##### Testing"""

from tensorflow.keras.models import load_model
saved_model = load_model('best_model.h5')

model_report(saved_model, model_history, evaluation_steps=None)

"""Εκπαιδεύοντας το μοντέλο, βλέπουμε learning curves παρόμοια με του VGG16 που μελετήσαμε παραπάνω, ενώ το test score: 81%. O χρόνος εκπαίδευσης είναι πιο μικρός από του VGG16. Επίσης, αύτη η τεχνική έχει ως αποτέλεσμα να μειώνει και την μνήμη που απαιτείται για την εκπαίδευση και το testing του μοντέλου.

#### VGG19

##### Αρχιτεκτονική VGG19

Έχοντας εκπαιδεύσει αρκετά μοντέλα με transfer learning του VGG-19, παρατηρήσαμε πως τα αποτελέσματά του ήταν σε γενικές γραμμές λίγο χειρότερα από του VGG-16.
"""

from tensorflow.keras import optimizers, layers
from tensorflow.keras.regularizers import l1

def VGG19(summary=True):
    # transfer learning: VGG19 trained on ImageNet without the top layer
    model = tf.keras.Sequential()

    # VGG19
    vgg = tf.keras.applications.VGG19(input_shape=(img_rows, img_cols, img_channels), 
                                                   include_top=False, weights='imagenet')

    model.add(vgg)
    model.add( layers.GlobalAveragePooling2D() )    
    model.add( layers.Dense(512, activation='relu') )
    model.add( layers.Dropout(rate = 0.35) )

    # Fully-connected output layer
    model.add( layers.Dense(100, activation='softmax') )

    model.compile(optimizer=optimizers.Adam(lr=0.0001), 
                  loss=tf.keras.losses.sparse_categorical_crossentropy, metrics=["accuracy"])
    if summary: 
        model.summary()
        
    return model

"""##### Φάση Εκπαίδευσης"""

BATCH_SIZE = 150

# Creating PrefetchDataset objects
train_ds =_input_fn(X_train, y_train, batch_size=BATCH_SIZE, reshuffle_each_iteration=True, repeat=True)
validation_ds =_input_fn(X_val, y_val, batch_size=BATCH_SIZE, reshuffle_each_iteration=False, repeat=False) 
test_ds =_input_fn(X_test, y_test, batch_size=1, reshuffle_each_iteration=False, repeat=False)

# Training
vgg19 = VGG19(summary=True)

# Checkpoint
from tensorflow.keras.callbacks import ModelCheckpoint
mc = ModelCheckpoint('best_model.h5', monitor='val_loss')

vgg19_history = train_model(vgg19, epochs=40, 
                            steps_per_epoch=np.ceil(X_train.shape[0] / BATCH_SIZE), 
                            callbacks=[mc],
                            validation_steps=None)

"""##### Testing"""

from tensorflow.keras.models import load_model
saved_vgg19 = load_model('best_model.h5')

model_report(saved_vgg19, vgg19_history, evaluation_steps=None)

"""Το test score που προέκυψε ήταν 78%. Σημειώνουμε πως το μοντέλο δεν έχει υποστεί data augmentation. Παρολά αυτά, ακόμα και με data augmentation δεν ξεπερνάει το 83% που είδαμε παραπάνω. Ωστόσο, το μοντέλο αυτό είναι πιο περίπλοκο από το VGG16, έχοντας παραπάνω παραμέτρους, αλλά δίχως κάποιο ουσιαστικό αποτελέσμα στην μελέτη μας.

# Συμπεράσματα

Στο σημείο αυτό, καλούμαστε να αναπαραστήσουμε τα αποτελέσματα που παρουσιάσαμε παραπάνω σε μία πιο γενική και κατανοητή μορφή. Για αυτό τον λόγο, παρουσιάζουμε με την μορφή πινάκων τα αποτελέσματα από τις αρχιτεκτονικές που μελετήσαμε.

<img src="nn_conclusions.png">

Παρατηρούμε πως τον ελάχιστο αριθμό παραμέτρων από τα βελτιστοποιημένα μοντέλα τον εμφανίζει το CNN4, που ωστόσο χρειάζεται τον μεγαλύτερο χρόνο εκπαίδευσης. Από την αλλή το μεγαλύτερο test score accuracy το εμφανίζει το VGG16 με 83%, έχοντας σχετικά μικρό χρόνο εκτέλεσης, δηλαδή περίπου 100 seconds πιο πολύ από το VGG16(s) που είναι πιο βέλτιστο στο χρόνο. Αν και τα μη βελτιστοποιημένα μοντέλα έχουν αρκετά μικρότερο χρόνο εκπαίδευσης, αυτό είναι αρκετά υποκειμενικό, αφού έχουν πολύ λιγότερες εποχές συγκριτικά με τις βελτιστοποιημένες υλοποιήσεις τους. Ακόμη, ο αριθμός των εποχών ίσως σε κάποια μοντέλα να είναι υπέρ αρκετός, αλλά, παρόλα αυτά, με την χρήση του Checkpoint, καταφέρνουμε να καταλήγουμε κάθε φορά με το επιθυμητό εκπαιδευμένο μοντέλο.

# What's next ?

Αφού έχουμε ολοκληρώσει την μελέτη μας στο πλαίσιο της τρίτης εργαστηριακής άσκησης, θα ήταν άξιο μελέτης να μελετήσουμε την προσαρμοστικότητα και τη συνέπεια των αρχιτεκτονικών μας σε ολόκληρο το CIFAR-100 dataset, στο οποίο έχει παρατηρηθεί μέχρι στιγμής επίδοση μέχρι και 92%.
"""